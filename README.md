# ğŸš€ Wafer Fault Detection System  
### End-to-End Machine Learning System with AI Explainability, Monitoring & CI/CD Deployment

---

## ğŸ“Œ Project Overview

This project is a production-grade Machine Learning system designed to detect faulty semiconductor wafers using sensor data.  
It goes beyond model training and covers the complete ML lifecycle, including:

- Data ingestion from MongoDB
- Feature transformation
- Model training & evaluation
- Batch prediction
- Real-time monitoring dashboard
- AI-powered explanation using Groq LLM
- Dockerized deployment with CI/CD on AWS EC2

ğŸ‘‰ This project simulates real-world industrial ML systems used in manufacturing quality control.

---

## ğŸ§  Problem Statement

In semiconductor manufacturing, faulty wafers lead to:
- Production loss
- Increased operational cost
- Quality degradation

The goal is to:
> Automatically classify wafers as Good or Bad using sensor readings  
> and provide explainable insights for engineers.

---

## ğŸ—ï¸ System Architecture (High Level)

ğŸ“Œ End-to-End Flow
## ğŸ—ï¸ System Architecture

### Data Ingestion
![Data Ingestion Architecture](<images/Data Ingestion.png>)

### Data Transformation
![Data Transformation Architecture](<images/Data Transformation.png>)

### Model Training
![Model Training Architecture](<images/Model Trainer.png>)

### Prediction Pipeline
![Data Transformation Architecture](<images/Prediction Pipeline.png>)

â”œâ”€â”€ src
â”‚   â”œâ”€â”€ components
â”‚   â”‚   â”œâ”€â”€ data_ingestion.py
â”‚   â”‚   â”œâ”€â”€ data_transformation.py
â”‚   â”‚   â”œâ”€â”€ model_trainer.py
â”‚   â”‚
â”‚   â”œâ”€â”€ pipeline
â”‚   â”‚   â”œâ”€â”€ train_pipeline.py
â”‚   â”‚   â”œâ”€â”€ predict_pipeline.py
â”‚   â”‚
â”‚   â”œâ”€â”€ monitoring
â”‚   â”‚   â””â”€â”€ metrics_utils.py
â”‚   â”‚
â”‚   â”œâ”€â”€ ai
â”‚   â”‚   â””â”€â”€ groq_assistant.py
â”‚   â”‚
â”‚   â”œâ”€â”€ utils
â”‚   â”‚   â””â”€â”€ main_utils.py
â”‚   â”‚
â”‚   â”œâ”€â”€ exception.py
â”‚   â”œâ”€â”€ logger.py
â”‚
â”œâ”€â”€ artifacts
â”‚   â”œâ”€â”€ model.pkl
â”‚   â”œâ”€â”€ preprocessor.pkl
â”‚   â””â”€â”€ metrics
â”‚       â””â”€â”€ prediction_metrics.json
â”‚
â”œâ”€â”€ templates
â”‚   â”œâ”€â”€ home.html
â”‚   â”œâ”€â”€ upload_file.html
â”‚   â”œâ”€â”€ dashboard.html
â”‚
â”œâ”€â”€ static
â”‚   â”œâ”€â”€ css
â”‚   â””â”€â”€ js
â”‚
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ app.py
â”œâ”€â”€ README.md



âš™ï¸ ML Pipeline Explanation
1ï¸âƒ£ Data Ingestion
Data fetched from MongoDB Atlas
Raw sensor data exported as CSV
Stored inside artifacts/
2ï¸âƒ£ Data Transformation
Missing value handling
Scaling using RobustScaler
Train-test split
Preprocessor saved as .pkl
3ï¸âƒ£ Model Training
Multiple models evaluated:
XGBoost
Random Forest
Gradient Boosting
SVM
Best model selected using validation accuracy
Hyperparameter tuning using GridSearchCV
4ï¸âƒ£ Prediction Pipeline
Batch CSV upload
Preprocessor + model loaded
Predictions generated
Output CSV downloaded
Metrics updated for dashboard
ğŸ“Š Monitoring Dashboard
The dashboard provides real-time ML monitoring, including:
Total predictions
Good vs Bad wafer count
Health score (% Good wafers)
Risk indicator bar
Trend analysis charts
Model name visibility
ğŸ“Œ Metrics are batch-wise (non-cumulative) for consistency.
ğŸ¤– AI Explainability (Groq LLM)
An AI assistant is integrated to explain prediction results.
LLM Provider: Groq
Model Used: llama-3.1-70b-versatile
Explains:
Why wafers are classified as bad
Overall quality insights
Engineering-friendly explanations
ğŸ“Œ AI runs independently of ML predictions (no hallucination).
â˜ï¸ Deployment & CI/CD
ğŸ³ Docker
Complete application containerized
Same behavior across environments
ğŸ” CI/CD Pipeline (GitHub Actions)
Triggered on every push
Steps:
Build Docker image
Push to AWS ECR
Deploy to AWS EC2 using self-hosted runner
â˜ï¸ AWS
EC2 (Ubuntu) as production server
ECR for Docker image registry
App exposed via public IP
â–¶ï¸ How to Run Locally
Copy code
Bash
# Clone repository
git clone <repo-url>
cd wafer-fault-detection

# Create virtual environment
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Run app
python app.py
ğŸ§ª How to Use
Open home page
Click Train Model
Upload CSV file for prediction
Download prediction results
Open Dashboard
Ask AI for explanation
ğŸ§  Key Engineering Learnings
Built a full ML system, not just a model
Solved real-world bugs (metrics inflation, AI config issues)
Designed modular, scalable architecture
Integrated AI explainability
Implemented CI/CD & cloud deployment

ğŸ™Œ Author
Armaan Joshi
Aspiring Data Scientist | Machine Learning | Computer Vision | MLOps
ğŸ“Œ This project demonstrates industry-level ML engineering practices.

