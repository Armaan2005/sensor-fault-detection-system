# ğŸš€ Wafer Fault Detection System  
### End-to-End Machine Learning System with AI Explainability, Monitoring & CI/CD Deployment

---

## ğŸ“Œ Project Overview

This project is a production-grade Machine Learning system designed to detect faulty semiconductor wafers using sensor data.  
It goes beyond model training and covers the complete ML lifecycle, including:

- Data ingestion from MongoDB
- Feature transformation
- Model training & evaluation
- Batch prediction
- Real-time monitoring dashboard
- AI-powered explanation using Groq LLM
- Dockerized deployment with CI/CD on AWS EC2

ğŸ‘‰ This project simulates real-world industrial ML systems used in manufacturing quality control.

---

## ğŸ§  Problem Statement

In semiconductor manufacturing, faulty wafers lead to:
- Production loss
- Increased operational cost
- Quality degradation

The goal is to:
> Automatically classify wafers as Good or Bad using sensor readings  
> and provide explainable insights for engineers.

---

## ğŸ—ï¸ System Architecture (High Level)

ğŸ“Œ End-to-End Flow
## ğŸ—ï¸ System Architecture

### Data Ingestion
![Data Ingestion Architecture](images/Data%20Ingestion.jpg)

### Data Transformation
![Data Transformation Architecture](<images/Data Transformation.jpg>)

### Model Training
![Model Training Architecture](<images/Model Trainer.jpg>)

### Prediction Pipeline
![Data Transformation Architecture](<images/Prediction Pipeline.jpg>)

â”œâ”€â”€ src
â”‚   â”œâ”€â”€ components
â”‚   â”‚   â”œâ”€â”€ data_ingestion.py
â”‚   â”‚   â”œâ”€â”€ data_transformation.py
â”‚   â”‚   â”œâ”€â”€ model_trainer.py
â”‚   â”‚
â”‚   â”œâ”€â”€ pipeline
â”‚   â”‚   â”œâ”€â”€ train_pipeline.py
â”‚   â”‚   â”œâ”€â”€ predict_pipeline.py
â”‚   â”‚
â”‚   â”œâ”€â”€ monitoring
â”‚   â”‚   â””â”€â”€ metrics_utils.py
â”‚   â”‚
â”‚   â”œâ”€â”€ ai
â”‚   â”‚   â””â”€â”€ groq_assistant.py
â”‚   â”‚
â”‚   â”œâ”€â”€ utils
â”‚   â”‚   â””â”€â”€ main_utils.py
â”‚   â”‚
â”‚   â”œâ”€â”€ exception.py
â”‚   â”œâ”€â”€ logger.py
â”‚
â”œâ”€â”€ artifacts
â”‚   â”œâ”€â”€ model.pkl
â”‚   â”œâ”€â”€ preprocessor.pkl
â”‚   â””â”€â”€ metrics
â”‚       â””â”€â”€ prediction_metrics.json
â”‚
â”œâ”€â”€ templates
â”‚   â”œâ”€â”€ home.html
â”‚   â”œâ”€â”€ upload_file.html
â”‚   â”œâ”€â”€ dashboard.html
â”‚
â”œâ”€â”€ static
â”‚   â”œâ”€â”€ css
â”‚   â””â”€â”€ js
â”‚
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ app.py
â”œâ”€â”€ README.md



### âš™ï¸ ML Pipeline Explanation

1ï¸âƒ£ Data Ingestion

  â€¢ Data fetched from MongoDB Atlas
  
  â€¢ Raw sensor data exported as CSV
  
  â€¢ Stored inside artifacts/
  
2ï¸âƒ£ Data Transformation

  â€¢ Missing value handling
  
  â€¢ Scaling using RobustScaler
  
  â€¢ Train-test split
  
  â€¢ Preprocessor saved as .pkl
  
3ï¸âƒ£ Model Training

  â€¢ Multiple models evaluated:
  
  â€¢ XGBoost
  
  â€¢ Random Forest
  
  â€¢ Gradient Boosting
  
  â€¢ SVM
  
  â€¢ Best model selected using validation accuracy
  
  â€¢ Hyperparameter tuning using GridSearchCV
  
4ï¸âƒ£ Prediction Pipeline

 â€¢ Batch CSV upload

 â€¢ Preprocessor + model loaded

 â€¢ Predictions generated

 â€¢ Output CSV downloaded

 â€¢ Metrics updated for dashboard

### ğŸ“Š Monitoring Dashboard

 â€¢ The dashboard provides real-time ML monitoring, including:
 
 â€¢ Total predictions
 
 â€¢ Good vs Bad wafer count
 
 â€¢ Health score (% Good wafers)
 
 â€¢ Risk indicator bar
 
 â€¢ Trend analysis charts
 
 â€¢ Model name visibility
 
ğŸ“Œ Metrics are batch-wise (non-cumulative) for consistency..


### ğŸ¤– AI Explainability (Groq LLM)

 â€¢ An AI assistant is integrated to explain prediction results.
 
 â€¢ LLM Provider: Groq
 
 â€¢ Model Used: llama-3.1-70b-versatile
 
 â€¢ Explains:
 
 â€¢ Why wafers are classified as bad
 
 â€¢ Overall quality insights
 
 â€¢ Engineering-friendly explanations
 
ğŸ“Œ AI runs independently of ML predictions (no hallucination).


### â˜ï¸ Deployment & CI/CD

## ğŸ³ Docker

 â€¢ Complete application containerized
 
 â€¢ Same behavior across environments
 
## ğŸ” CI/CD Pipeline (GitHub Actions)

 â€¢ Triggered on every push
 
 â€¢ Steps:
 
 â€¢ Build Docker image
   
 â€¢ Push to AWS ECR
   
 â€¢ Deploy to AWS EC2 using self-hosted runner
 
## â˜ï¸ AWS

 â€¢ EC2 (Ubuntu) as production server
 
 â€¢ ECR for Docker image registry
 
 â€¢ App exposed via public IP

### â–¶ï¸ How to Run Locally

Copy code

Bash

# Clone repository

git clone <repo-url>

cd wafer-fault-detection

# Create virtual environment

python -m venv venv

source venv/bin/activate  # Windows: venv\Scripts\activate

# Install dependencies

pip install -r requirements.txt

# Run app

python app.py

ğŸ§ª How to Use

Open home page

Click Train Model

Upload CSV file for prediction

Download prediction results

Open Dashboard

Ask AI for explanation

ğŸ§  Key Engineering Learnings

Built a full ML system, not just a model

Solved real-world bugs (metrics inflation, AI config issues)

Designed modular, scalable architecture

Integrated AI explainability

Implemented CI/CD & cloud deployment

ğŸ™Œ Author

Armaan Joshi

Aspiring Data Scientist | Machine Learning | Computer Vision | MLOps

ğŸ“Œ This project demonstrates industry-level ML engineering practices.

